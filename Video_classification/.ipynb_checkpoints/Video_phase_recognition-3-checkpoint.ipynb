{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using a CNN trained for LC texture phase classification to classify LC phase transition videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Aim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this notebook is to prove the concept of using a CNN, trained for detecting the phase of a texture between Isotropic, Nematic, SmA, SmF, and Cholesteric, for detecting what phase is present in a video of a LC undergoing a phase transition. The approach will be to train a CNN on LC texture images \"good\" LC texture classifier. Then, this trained CNN will be applied to the frames of a test video to predict, for each frame, what phase is present in the video. It will hopefully be able to notice phase transitions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data leakage is important in this task, it should be made sure that images used to train the CNN are not from videos used when testing. Equally, in the training of the CNN for image classification, it should be made sure that training images and validation images do not come from the same videos (images for this task may have been obtained by using VLC for grabbing frames of LC videos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_title = \"Video_phase_recognition3\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras import Model\n",
    "from keras import layers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Retrieving data and image preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_directory = \"C:/Users/Jason/Documents/University/Year_4/MPhys_Project(s)/Liquid_crystals-machine_learning/(I,N,Chol,Sm)Images\"\n",
    "\n",
    "train_dir = img_directory + \"/Train\"\n",
    "val_dir = img_directory + \"/Val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3378 images belonging to 4 classes.\n",
      "Found 1737 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1/255,\n",
    "                                   rotation_range = 45,\n",
    "                                   width_shift_range = 0.3,\n",
    "                                   height_shift_range = 0.3,\n",
    "                                   zoom_range = 0.3,\n",
    "                                   horizontal_flip = True,\n",
    "                                   vertical_flip = True\n",
    "                                  )\n",
    "val_datagen = ImageDataGenerator(rescale = 1/255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    batch_size = 16,\n",
    "                                                    class_mode = \"categorical\",\n",
    "                                                    color_mode = \"grayscale\",\n",
    "                                                    target_size = (256, 256)\n",
    "                                                   )\n",
    "val_generator = val_datagen.flow_from_directory(val_dir,\n",
    "                                                batch_size = 16,\n",
    "                                                class_mode = \"categorical\",\n",
    "                                                color_mode = \"grayscale\",\n",
    "                                                target_size = (256,256)\n",
    "                                               )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 252, 252, 32)      832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 126, 126, 32)      0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 126, 126, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 124, 124, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 62, 62, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 62, 62, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 60, 60, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 30, 30, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 30, 30, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 28, 28, 256)       295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              263168    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 1028      \n",
      "=================================================================\n",
      "Total params: 914,948\n",
      "Trainable params: 914,948\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    layers.Conv2D(32, kernel_size=(5,5), activation = \"relu\", input_shape=(256,256,1)),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "    layers.Dropout(0.3),\n",
    "    \n",
    "    layers.Conv2D(64, kernel_size=(3,3), activation = \"relu\"),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "    layers.Dropout(0.3),\n",
    "    \n",
    "    layers.Conv2D(128, kernel_size=(3,3), activation = \"relu\"),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "    layers.Dropout(0.4),\n",
    "    \n",
    "    layers.Conv2D(256, kernel_size=(3,3), activation = \"relu\"),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "    layers.Dropout(0.4),\n",
    "    \n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(1024, activation=\"relu\"),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(256, activation=\"relu\"),\n",
    "    layers.Dropout(0.5),\n",
    "    \n",
    "    layers.Dense(4, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_dir = \"C:/Users/Jason/Documents/University/Year_4/MPhys_Project(s)/\" + str(file_title) + \"_saved_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 57/212 [=======>......................] - ETA: 3:33 - loss: 1.1186 - accuracy: 0.4781"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "checkpoint = ModelCheckpoint(model_save_dir, monitor = \"val_accuracy\", save_best_only = True, mode=\"max\")\n",
    "history = model.fit(train_generator,\n",
    "                    validation_data=val_generator,\n",
    "                    epochs=100,\n",
    "                    callbacks=[checkpoint],\n",
    "                    verbose=1\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Want to save the data incase I want to plot it alongside other training data graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "train_data_file_path = \"C:/Users/Jason/Documents/University/Year_4/MPhys_Project(s)/Liquid_crystals-machine_learning/LiquidCrystalMachineLearning/Video_classification/\" + str(file_title) + \"_training_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = np.array(acc).reshape(len(acc), 1)\n",
    "val_acc = np.array(val_acc).reshape(len(val_acc), 1)\n",
    "loss = np.array(loss).reshape(len(loss), 1)\n",
    "val_loss = np.array(val_loss).reshape(len(val_loss), 1)\n",
    "\n",
    "training_log = np.hstack((acc, val_acc, loss, val_loss))\n",
    "\n",
    "column_headers = [\"Training accuracy\", \"Validation accuracy\", \"Training loss\", \"Validation loss\"]\n",
    "\n",
    "df = pd.DataFrame(data = training_log, columns = column_headers)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(train_data_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the training and validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.figure(figsize=(10,9))\n",
    "\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(epochs, acc, 'r', label=\"Training Accuracy\")\n",
    "plt.plot(epochs, val_acc, 'b', label=\"Validation Accuracy\")\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend(loc=0)\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(epochs, loss, 'r', label=\"Training Loss\")\n",
    "plt.plot(epochs, val_loss, 'b', label=\"Validation Loss\")\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend(loc=0)\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "plt.savefig(str(file_title) + \"-train_val_graph\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Testing trained model on images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_load_dir = \"C:/Users/Jason/Documents/University/Year_4/MPhys_Project(s)/\" + str(file_title) + \"_saved_model\"\n",
    "trained_model = tf.keras.models.load_model(model_load_dir)\n",
    "\n",
    "for layer in trained_model.layers:\n",
    "  layer.trainable = False\n",
    "\n",
    "trained_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix and classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_val_datagen = ImageDataGenerator(rescale = 1/255)\n",
    "fixed_val_generator = fixed_val_datagen.flow_from_directory(val_dir,\n",
    "                                                batch_size = 16,\n",
    "                                                class_mode = \"categorical\",\n",
    "                                                color_mode = \"grayscale\",\n",
    "                                                target_size = (256,256),\n",
    "                                                shuffle = False\n",
    "                                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = trained_model.predict(fixed_val_generator, batch_size=16, verbose=1)\n",
    "y_pred = np.argmax(predictions, axis=1)\n",
    "\n",
    "y_true = fixed_val_generator.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, target_names, title='Confusion matrix', cmap=None, normalize=True, save=True):\n",
    "    \"\"\"\n",
    "    from: https://www.kaggle.com/grfiv4/plot-a-confusion-matrix\n",
    "    \"\"\"\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "    \n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    \n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    \n",
    "    if save:\n",
    "        plt.savefig(str(file_title) + \"-confusion_matrix\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true, y_pred)\n",
    "target_names = [\"Isotropic\", \"Nematic\", \"Cholesteric\", \"Smectic\"]\n",
    "\n",
    "plot_confusion_matrix(cm,\n",
    "                      target_names,\n",
    "                      title=\"Confusion matrix\",\n",
    "                      normalize=True,\n",
    "                      save=True\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Testing trained model on a video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 1\n",
    "queue = collections.deque(maxlen=size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_file_name = \"M6-Green_80C_Crystalize\"\n",
    "vid_path = \"C:/Users/Jason/Documents/University/Year_4/MPhys_Project(s)/Liquid_crystals-machine_learning/(I,N,Chol,Sm)Test_videos/M6/\" + video_file_name + \".avi\"\n",
    "vid_save_path = file_title + \"_\" + video_file_name + \".avi\"\n",
    "vid_stream = cv2.VideoCapture(vid_path)\n",
    "\n",
    "writer = None\n",
    "width = int(vid_stream.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(vid_stream.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = vid_stream.get(cv2.CAP_PROP_FPS)\n",
    "fourcc = int(vid_stream.get(cv2.CAP_PROP_FOURCC))\n",
    "\n",
    "while True:\n",
    "    (grabbed, frame) = vid_stream.read()\n",
    "    if not grabbed:\n",
    "        break\n",
    "        \n",
    "    output_vid = frame.copy()\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    frame = cv2.resize(frame, (254, 254)).astype(\"float32\") / 255\n",
    "    \n",
    "    pred = trained_model.predict(np.expand_dims(frame, axis=(0,3)))\n",
    "    y_predict = np.argmax(pred, axis=1)\n",
    "    confidence = pred[0][y_predict]\n",
    "    queue.append(pred)\n",
    "    \n",
    "    results = np.array(queue).mean(axis=0)\n",
    "    i = np.argmax(results)\n",
    "    label = target_names[i]\n",
    "    \n",
    "    phase_text = \"Phase: {}\".format(label)\n",
    "    phase_confidence_text = \"Confidence: {}\".format(confidence)\n",
    "    cv2.putText(output_vid, phase_text, (35,50), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "               1.25, (255, 255, 255), 5)\n",
    "    cv2.putText(output_vid, phase_confidence_text, (35,90), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "               1.25, (255, 255, 255), 5)\n",
    "    \n",
    "    if writer is None:\n",
    "        writer = cv2.VideoWriter(vid_save_path, fourcc, fps, (width, height), True)\n",
    "        \n",
    "    writer.write(output_vid)\n",
    "    \n",
    "    cv2.imshow(\"Output_vid\", output_vid)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    \n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "        \n",
    "\n",
    "writer.release()\n",
    "vid_stream.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
