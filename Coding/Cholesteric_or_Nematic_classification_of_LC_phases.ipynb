{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook was created at 18:54 17/10/20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cholesteric or Nematic classification of liquid crystal phases using deep learning techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim is to advance upon previous notebooks that attempted to perform multi_class phase classification from LC textures by using a balanced dataset (only nematic and cholesteric due to a lack of images for other phases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers.experimental.preprocessing import Rescaling\n",
    "from keras.preprocessing import image_dataset_from_directory\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 316 files belonging to 2 classes.\n",
      "Found 35 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_directory = \"C:/Users/Jason/Documents/University/Year_4/MPhys_Project(s)/Liquid_crystals-machine_learning/LiquidCrystalMachineLearning/Images_balanced/Train\"\n",
    "test_directory = \"C:/Users/Jason/Documents/University/Year_4/MPhys_Project(s)/Liquid_crystals-machine_learning/LiquidCrystalMachineLearning/Images_balanced/Test\"\n",
    "image_size = (368,640)\n",
    "\n",
    "# Change images to grayscale as colour isnt an important feature at this stage\n",
    "train_dataset = image_dataset_from_directory(train_directory,\n",
    "                            labels=\"inferred\",\n",
    "                            label_mode=\"categorical\",\n",
    "                            color_mode=\"grayscale\",\n",
    "                            batch_size=64,\n",
    "                            image_size=image_size,\n",
    "                            shuffle=True\n",
    "                        )\n",
    "val_dataset = image_dataset_from_directory(test_directory,\n",
    "                            labels=\"inferred\",\n",
    "                            label_mode=\"categorical\",\n",
    "                            color_mode=\"grayscale\",\n",
    "                            batch_size=64,\n",
    "                            image_size=image_size,\n",
    "                            shuffle=True\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if the files imported as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TensorSpec(shape=(None, 368, 640, 1), dtype=tf.float32, name=None), TensorSpec(shape=(None, 2), dtype=tf.float32, name=None))\n",
      "['Cholesteric', 'Nematic']\n",
      "(64, 368, 640, 1)\n",
      "<dtype: 'float32'>\n",
      "(64, 2)\n",
      "<dtype: 'float32'>\n",
      "(64, 368, 640, 1)\n",
      "<dtype: 'float32'>\n",
      "(64, 2)\n",
      "<dtype: 'float32'>\n",
      "(64, 368, 640, 1)\n",
      "<dtype: 'float32'>\n",
      "(64, 2)\n",
      "<dtype: 'float32'>\n",
      "(64, 368, 640, 1)\n",
      "<dtype: 'float32'>\n",
      "(64, 2)\n",
      "<dtype: 'float32'>\n",
      "(60, 368, 640, 1)\n",
      "<dtype: 'float32'>\n",
      "(60, 2)\n",
      "<dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.element_spec)\n",
    "print(train_dataset.class_names)\n",
    "for data, labels in train_dataset:\n",
    "    print(data.shape)\n",
    "    print(data.dtype)\n",
    "    print(labels.shape)\n",
    "    print(labels.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TensorSpec(shape=(None, 368, 640, 1), dtype=tf.float32, name=None), TensorSpec(shape=(None, 2), dtype=tf.float32, name=None))\n",
      "['Cholesteric', 'Nematic']\n",
      "(35, 368, 640, 1)\n",
      "<dtype: 'float32'>\n",
      "(35, 2)\n",
      "<dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "print(val_dataset.element_spec)\n",
    "print(val_dataset.class_names)\n",
    "for data, labels in val_dataset:\n",
    "    print(data.shape)\n",
    "    print(data.dtype)\n",
    "    print(labels.shape)\n",
    "    print(labels.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define out pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shape = (image_size[0], image_size[1], 1)\n",
    "X_inputs = Input(shape = image_shape)\n",
    "# Rescale images to have values in range [0,1]\n",
    "X = Rescaling(scale = 1/255)(X_inputs)\n",
    "\n",
    "\n",
    "# Apply convolutional and pooling layers\n",
    "X = Conv2D(filters=32, kernel_size=(3,3), activation=\"relu\")(X)\n",
    "X = MaxPooling2D(pool_size=(3,3))(X)\n",
    "X = Conv2D(filters=32, kernel_size=(3,3), activation=\"relu\")(X)\n",
    "X = MaxPooling2D(pool_size=(3,3))(X)\n",
    "\n",
    "# Apply fully connected layer\n",
    "X = Flatten()(X)\n",
    "X = Dense(units=128, activation=\"relu\")(X)\n",
    "X = Dense(units=64, activation=\"relu\")(X)\n",
    "# Output layer\n",
    "num_classes = 2\n",
    "X_outputs = Dense(units=num_classes, activation=\"softmax\")(X)\n",
    "\n",
    "model = Model(inputs = X_inputs, outputs = X_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what this model looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, 368, 640, 1)]     0         \n",
      "_________________________________________________________________\n",
      "rescaling_4 (Rescaling)      (None, 368, 640, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 366, 638, 32)      320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 122, 212, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 120, 210, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 40, 70, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 89600)             0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 128)               11468928  \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 11,486,882\n",
      "Trainable params: 11,486,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to compile, train and test the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "5/5 [==============================] - 16s 3s/step - loss: 1.1078 - accuracy: 0.5538\n",
      "Epoch 2/15\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.3729 - accuracy: 0.8449\n",
      "Epoch 3/15\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2026 - accuracy: 0.9462\n",
      "Epoch 4/15\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.0833 - accuracy: 0.9810\n",
      "Epoch 5/15\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.0316 - accuracy: 1.0000\n",
      "Epoch 6/15\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.0142 - accuracy: 1.0000\n",
      "Epoch 7/15\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 8/15\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 9/15\n",
      "5/5 [==============================] - 15s 3s/step - loss: 8.6000e-04 - accuracy: 1.0000\n",
      "Epoch 10/15\n",
      "5/5 [==============================] - 16s 3s/step - loss: 4.5522e-04 - accuracy: 1.0000\n",
      "Epoch 11/15\n",
      "5/5 [==============================] - 15s 3s/step - loss: 2.3267e-04 - accuracy: 1.0000\n",
      "Epoch 12/15\n",
      "5/5 [==============================] - 15s 3s/step - loss: 1.8932e-04 - accuracy: 1.0000\n",
      "Epoch 13/15\n",
      "5/5 [==============================] - 15s 3s/step - loss: 1.1474e-04 - accuracy: 1.0000\n",
      "Epoch 14/15\n",
      "5/5 [==============================] - 15s 3s/step - loss: 9.8479e-05 - accuracy: 1.0000\n",
      "Epoch 15/15\n",
      "5/5 [==============================] - 14s 3s/step - loss: 8.8328e-05 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21e4bf3da08>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataset, epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how the model does on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 760us/step - loss: 1.5283 - accuracy: 0.7143\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the confusion matrix on our predictions to understand how our model is performing on the unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(val_dataset)\n",
    "y_pred = np.argmax(predictions, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 0 0 1 1 0 1 1 1 1 0 1 0 1 0 1 1 1 1 0 0 0 0 0 0 1 0 0 0 1 0 0 1]\n",
      "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 1 0 0 0 0 0 1 1 1 0 0 0 0]\n",
      "Confusion matrix:\n",
      "[[0.63157895 0.36842105]\n",
      " [0.9375     0.0625    ]]\n"
     ]
    }
   ],
   "source": [
    "# Get true labels\n",
    "y_true = np.argmax(np.concatenate([labels for data, labels in val_dataset], axis=0), axis=1)\n",
    "print(y_true)\n",
    "print(y_pred)\n",
    "\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(y_true=y_true, y_pred=y_pred, normalize=\"true\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An imbalnced training dataset (many more cholesteric images than other phases) is one major flaw with the current model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
