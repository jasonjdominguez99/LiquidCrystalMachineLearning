{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook was created at 11:34 14/10/20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary classification of liquid crystal (LC) textures into Cholesteric phase or non-Cholesteric phase using a CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook advances on the work done in previous notebooks (binary classification between LC phase or isotropic phase) by extending this to distinguishing between one particular LC phase (Cholesteric) and any others. \n",
    "\n",
    "Cholesteric was chosen as, at the current time, this is the phase for which there are the most images/videos.\n",
    "\n",
    "The LC phases will be represented by textures obtained via Youtube videos - (Vance Williams channel).\n",
    "\n",
    "Specifically this classification will be implemented using a simple convolutional network (CNN) - LeNet-5 inspired - as this is a CNN that is not to computationally expensive for this task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be using keras and/or tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow keras numpy matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to get the image files into a usuable format (numpy.array). The images will be 368(height)x640(width) (the size of the pictures taken from Youtube videos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images(N_images, steps, video_filename, file_type, total_image_array, total_label_array, label):\n",
    "    \n",
    "    shape = (1, total_image_array.shape[1], total_image_array.shape[2],  total_image_array.shape[3])\n",
    "    label_reshaped = np.array([label]).reshape(1,1)\n",
    "    \n",
    "    for i in range(1, N_images+1, steps):\n",
    "        image = np.array(Image.open(str(video_filename) + \"%05d\"%(i) + str(file_type))).reshape(shape) / 255\n",
    "        total_image_array = np.concatenate((total_image_array, image), axis = 0)\n",
    "        total_label_array = np.concatenate((total_label_array, label_reshaped), axis = 0)\n",
    "        \n",
    "    print(str(video_filename) + \" images loaded!\")\n",
    "    \n",
    "    return total_image_array, total_label_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(image_shape):\n",
    "    \"\"\"\n",
    "    Get data from images obtained from YouTube - must make sure that images from the same video are not\n",
    "    spread between the training set and validation or test set - to prevent data leakage.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image_shape : tuple\n",
    "        Shape of images we're dealing with\n",
    "    N_isotropic : int\n",
    "        Number of isotropic examples we're generating for the dataset\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    images_shuffled : np.array\n",
    "        Shuffled images that were generated of size (N_examples, image height, image width, 1)\n",
    "    labels_shuffled : np.array\n",
    "        Labels corresponding to the shuffled images, 1 for LC and 0 for isotropic, of size (N_examples, 1)\n",
    "\n",
    "    \"\"\"\n",
    "    height = image_shape[0]\n",
    "    width = image_shape[1]\n",
    "    \n",
    "    # Get Youtube LC images and labels (1 for cholesteric, 0 else)\n",
    "    vid_file_path = \"C:/Users/Jason/Documents/University/Year_4/MPhys_Project(s)/Liquid_crystals-machine_learning/LiquidCrystalMachineLearning/Images/\"\n",
    "    \n",
    "    # training data\n",
    "    images_train = np.zeros((1, height, width, 3)) # we'll need to remove this entry of zeros\n",
    "    labels_train = np.zeros((1,1)) # we'll need to remove this entry of zeros\n",
    "    images_train, labels_train = get_images(541, 10, vid_file_path + \"Youtube_Vance_Williams-Focal_Conic_Smectic_A\", \".jpeg\", images_train, labels_train, label = 0)\n",
    "    images_train, labels_train = get_images(541, 10, vid_file_path + \"Youtube_Vance_Williams-Youtube_Vance_Williams-Smectic_F_Isotropic_flucuations\", \".jpeg\", images_train, labels_train, label = 0) # isotropic frames (1,11,1001,1011,1021,1901,1911,1921,1931,1941,2111,2121)\n",
    "    images_train, labels_train = get_images(541, 10, vid_file_path + \"Youtube_Vance_Williams-Youtube_Vance_Williams-Youtube-Vance_Williams-Cholesteric(2)\", \".jpeg\", images_train, labels_train, label = 1)\n",
    "    images_train, labels_train = get_images(541, 10, vid_file_path + \"Youtube-Vance_Williams-Cholesteric_droplets\", \".jpeg\", images_train, labels_train, label = 1)\n",
    "    images_train, labels_train = get_images(541, 10, vid_file_path + \"Youtube-Vance_Williams-Cholesteric_fluctuations\", \".jpeg\", images_train, labels_train, label = 1)\n",
    "    images_train, labels_train = get_images(541, 10, vid_file_path + \"Youtube-Vance_Williams-Cholesteric_to_Isotropic\", \".jpeg\", images_train, labels_train, label = 1)\n",
    "    images_train, labels_train = get_images(541, 10, vid_file_path + \"Youtube-Vance_Williams-Isotropic_to_Cholesteric_transition\", \".jpeg\", images_train, labels_train, label = 1)\n",
    "    images_train, labels_train = get_images(541, 10, vid_file_path + \"Youtube-Vance_Williams-Isotropic_to_Nematic\", \".jpeg\", images_train, labels_train, label = 0) # isotropic frames (upto and including 141)\n",
    "    images_train, labels_train = get_images(541, 10, vid_file_path + \"Youtube-Vance_Williams-Isotropic_to_Smectic_F(2)\", \".jpeg\", images_train, labels_train, label = 0) # isotropic frames (upto and including 61)    \n",
    "    images_train, labels_train = get_images(541, 10, vid_file_path + \"Youtube-Vance_Williams-Nematic\", \".jpeg\", images_train, labels_train, label = 0)\n",
    "    images_train, labels_train = get_images(541, 10, vid_file_path + \"Youtube-Vance_Williams-Smectic\", \".jpeg\", images_train, labels_train, label = 0)\n",
    "    # Not included as they are complex to label\n",
    "    #get_images(811, 10, vid_file_path + \"Youtube-Vance_Williams-Nematic_to_Smectic_A\", \".jpeg\", images_LC_test)\n",
    "    #get_images(631, 10, vid_file_path + \"Youtube-Vance_Williams-Youtube-Vance_Williams-Smectic_C_to_Nematic_transition\", \".jpeg\", images_LC_test)\n",
    "    \n",
    "    labels_train = np.delete(labels_train, 0, axis = 0)\n",
    "    images_train = np.delete(images_train, 0, axis = 0)\n",
    "    \n",
    "    images_train_shuffled, labels_train_shuffled = shuffle(images_train, labels_train)\n",
    "    \n",
    "    # holdout (val/test) data (no images that will be trained on, to avoid data leakage)\n",
    "    images_holdout = np.zeros((1, height, width, 3))\n",
    "    labels_holdout = np.zeros((1,1)) # we'll need to remove this entry of zeros\n",
    "    images_holdout, labels_holdout = get_images(551, 10, vid_file_path + \"Youtube-Vance_Williams-Cholesteric_heating\", \".jpeg\", images_holdout, labels_holdout, label = 1)\n",
    "    images_holdout, labels_holdout = get_images(841, 10, vid_file_path + \"Youtube-Vance_Williams-Cholesteric_to_Isotropic_transition\", \".jpeg\", images_holdout, labels_holdout, label = 1)\n",
    "    images_holdout, labels_holdout = get_images(781, 10, vid_file_path + \"Youtube-Vance_Williams-Cholesteric\", \".jpeg\", images_holdout, labels_holdout, label = 1)\n",
    "    images_holdout, labels_holdout = get_images(551, 10, vid_file_path + \"Youtube-Vance_Williams-Nematic_droplets_in_Isotropic\", \".jpeg\", images_holdout, labels_holdout, label = 0)\n",
    "    images_holdout, labels_holdout = get_images(361, 10, vid_file_path + \"Youtube-Vance_Williams-Isotropic_to_Smectic_F\", \".jpeg\", images_holdout, labels_holdout, label = 0) # isotropic frames (upto and including 61)\n",
    "    \n",
    "    labels_holdout = np.delete(labels_holdout, 0, axis = 0)\n",
    "    images_holdout = np.delete(images_holdout, 0, axis = 0)\n",
    "\n",
    "    # from the holdout data, genereate the validation and test datasets\n",
    "    images_val, images_test, labels_val, labels_test = train_test_split(images_holdout, labels_holdout, test_size=0.5)\n",
    "    \n",
    "    print(\"All data loaded and shuffled!\")\n",
    "    \n",
    "    return images_train_shuffled, labels_train_shuffled, images_val, labels_val, images_test, labels_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate some data. (This could take a minute or so.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/Jason/Documents/University/Year_4/MPhys_Project(s)/Liquid_crystals-machine_learning/LiquidCrystalMachineLearning/Images/Youtube_Vance_Williams-Focal_Conic_Smectic_A images loaded!\n",
      "C:/Users/Jason/Documents/University/Year_4/MPhys_Project(s)/Liquid_crystals-machine_learning/LiquidCrystalMachineLearning/Images/Youtube_Vance_Williams-Youtube_Vance_Williams-Smectic_F_Isotropic_flucuations images loaded!\n",
      "C:/Users/Jason/Documents/University/Year_4/MPhys_Project(s)/Liquid_crystals-machine_learning/LiquidCrystalMachineLearning/Images/Youtube_Vance_Williams-Youtube_Vance_Williams-Youtube-Vance_Williams-Cholesteric(2) images loaded!\n",
      "C:/Users/Jason/Documents/University/Year_4/MPhys_Project(s)/Liquid_crystals-machine_learning/LiquidCrystalMachineLearning/Images/Youtube-Vance_Williams-Cholesteric_droplets images loaded!\n",
      "C:/Users/Jason/Documents/University/Year_4/MPhys_Project(s)/Liquid_crystals-machine_learning/LiquidCrystalMachineLearning/Images/Youtube-Vance_Williams-Cholesteric_fluctuations images loaded!\n",
      "C:/Users/Jason/Documents/University/Year_4/MPhys_Project(s)/Liquid_crystals-machine_learning/LiquidCrystalMachineLearning/Images/Youtube-Vance_Williams-Cholesteric_to_Isotropic images loaded!\n",
      "C:/Users/Jason/Documents/University/Year_4/MPhys_Project(s)/Liquid_crystals-machine_learning/LiquidCrystalMachineLearning/Images/Youtube-Vance_Williams-Isotropic_to_Cholesteric_transition images loaded!\n",
      "C:/Users/Jason/Documents/University/Year_4/MPhys_Project(s)/Liquid_crystals-machine_learning/LiquidCrystalMachineLearning/Images/Youtube-Vance_Williams-Isotropic_to_Nematic images loaded!\n",
      "C:/Users/Jason/Documents/University/Year_4/MPhys_Project(s)/Liquid_crystals-machine_learning/LiquidCrystalMachineLearning/Images/Youtube-Vance_Williams-Isotropic_to_Smectic_F(2) images loaded!\n",
      "C:/Users/Jason/Documents/University/Year_4/MPhys_Project(s)/Liquid_crystals-machine_learning/LiquidCrystalMachineLearning/Images/Youtube-Vance_Williams-Nematic images loaded!\n",
      "C:/Users/Jason/Documents/University/Year_4/MPhys_Project(s)/Liquid_crystals-machine_learning/LiquidCrystalMachineLearning/Images/Youtube-Vance_Williams-Smectic images loaded!\n",
      "C:/Users/Jason/Documents/University/Year_4/MPhys_Project(s)/Liquid_crystals-machine_learning/LiquidCrystalMachineLearning/Images/Youtube-Vance_Williams-Cholesteric_heating images loaded!\n",
      "C:/Users/Jason/Documents/University/Year_4/MPhys_Project(s)/Liquid_crystals-machine_learning/LiquidCrystalMachineLearning/Images/Youtube-Vance_Williams-Cholesteric_to_Isotropic_transition images loaded!\n",
      "C:/Users/Jason/Documents/University/Year_4/MPhys_Project(s)/Liquid_crystals-machine_learning/LiquidCrystalMachineLearning/Images/Youtube-Vance_Williams-Cholesteric images loaded!\n",
      "C:/Users/Jason/Documents/University/Year_4/MPhys_Project(s)/Liquid_crystals-machine_learning/LiquidCrystalMachineLearning/Images/Youtube-Vance_Williams-Nematic_droplets_in_Isotropic images loaded!\n",
      "C:/Users/Jason/Documents/University/Year_4/MPhys_Project(s)/Liquid_crystals-machine_learning/LiquidCrystalMachineLearning/Images/Youtube-Vance_Williams-Isotropic_to_Smectic_F images loaded!\n",
      "All data loaded and shuffled!\n"
     ]
    }
   ],
   "source": [
    "image_shape = (368,640)\n",
    "images_train, labels_train, images_val, labels_val, images_test, labels_test = generate_data(image_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some of the images and make sure the labels are matching up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 100\n",
    "plt.imshow(images_train[index,:,:,:])\n",
    "print(\"Label: %i\"%labels_train[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 100\n",
    "plt.imshow(images_test[3,:,:,:])\n",
    "print(\"Label: %i\"%labels_test[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"number of training examples = \" + str(images_train.shape[0]))\n",
    "print (\"number of validation examples = \" + str(images_val.shape[0]))\n",
    "print (\"number of test examples = \" + str(images_test.shape[0]))\n",
    "print (\"X_train shape: \" + str(images_train.shape))\n",
    "print (\"Y_train shape: \" + str(labels_train.shape))\n",
    "print (\"X_val shape: \" + str(images_val.shape))\n",
    "print (\"Y_val shape: \" + str(labels_val.shape))\n",
    "print (\"X_test shape: \" + str(images_test.shape))\n",
    "print (\"Y_test shape: \" + str(labels_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the LeNet-5 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leNet5(input_shape):\n",
    "    \"\"\"\n",
    "    Create an instance of model class representing LeNet-5\n",
    "    inspired architecture\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_shape : tuple\n",
    "        shape to be input to the CNN\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    model : instance of model class\n",
    "        our LeNet-5 inspired model\n",
    "\n",
    "    \"\"\"\n",
    "    # Input placeholder with shape input_shape\n",
    "    X_input = Input(input_shape)\n",
    "    \n",
    "    # Apply 6 5x5 filter convolution with stride of 1\n",
    "    X = Conv2D(6, (5,5), strides = (1,1), activation = \"relu\", name = \"conv1\")(X_input)\n",
    "    # Apply maxpooling with a filter size of 2x2 and stride of 2\n",
    "    X = MaxPooling2D((2,2), strides = (2,2), name = \"max_pool1\")(X)\n",
    "    # Apply 16 5x5 filter convolution with stride of 1\n",
    "    X = Conv2D(16, (5,5), strides = (1,1), activation = \"relu\", name = \"conv2\")(X)\n",
    "    # Apply maxpooling with a filter size of 2x2 and stride 2\n",
    "    X = MaxPooling2D((2,2), strides = (2,2), name = \"max_pool2\")(X)\n",
    "    \n",
    "    # Flatten X (convert to a vector) before going to fully\n",
    "    # connected layers\n",
    "    X = Flatten()(X)\n",
    "    # Apply fully connected layer with 120 neurons\n",
    "    X = Dense(120, activation=\"relu\", name = \"fc3\")(X)\n",
    "    # Apply fully connected layer with 120 neurons\n",
    "    X = Dense(84, activation=\"relu\", name = \"fc5\")(X)\n",
    "    \n",
    "    # Output a single binary classification\n",
    "    X = Dense(1, activation=\"sigmoid\", name = \"fc_out\")(X)\n",
    "    \n",
    "    # Create Keras model instance\n",
    "    model = Model(inputs = X_input, outputs = X, name=\"LeNet-5\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LeNet5_model = leNet5(images_train.shape[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LeNet5_model.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LeNet5_model.fit(x = images_train, y = labels_train, epochs = 4, batch_size = 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get accuracy on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = LeNet5_model.evaluate(x = images_val, y = labels_val)\n",
    "print()\n",
    "print(\"Validation accuracy = \" + str(test[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = LeNet5_model.predict(images_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 149\n",
    "plt.imshow(images_test[index,:,:,:])\n",
    "print(\"Label: %i\"%labels_test[index])\n",
    "print(\"Prediction: %i\"%prediction[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prediction.shape)\n",
    "print(labels_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(prediction)):\n",
    "    if prediction[i] == 1:\n",
    "        print(\"Predicted that \" + str(i) + \" was cholesteric.\")\n",
    "        \n",
    "for i in range(len(labels_test)):\n",
    "    if labels_test[i] == 1:\n",
    "        print(str(i) + \" actually was cholesteric.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few things to note from this notebook.\n",
    "1. Its becomes impractically time consuming to get all the images read in from the local disk in the way done in this notebook. Possible work arounds are creating a database for the images and labels - possibly using h5py (python's HDF5 library)\n",
    "2. The algorithms is currently overfitting the training data. Despite performing well in the training data (\\~100%), it does not generalise well to unseen data (~60% - little better than randomly guessing). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the aim of increasing the accuracy on the validation set, we will now try to reduce overfitting. It can never hurt to have more data, however for now the computation time is an issue (see point 1 above). We can try adding dropout layers to the CNN and increasing the training epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_with_dropout(input_shape):\n",
    "    \"\"\"\n",
    "    Create an instance of model class representing LeNet-5\n",
    "    inspired architecture\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_shape : tuple\n",
    "        shape to be input to the CNN\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    model : instance of model class\n",
    "        our LeNet-5 inspired model\n",
    "\n",
    "    \"\"\"\n",
    "    # Input placeholder with shape input_shape\n",
    "    X_input = Input(input_shape)\n",
    "    \n",
    "    # Apply 6 5x5 filter convolution with stride of 1\n",
    "    X = Conv2D(6, (5,5), strides = (1,1), activation = \"relu\", name = \"conv1\")(X_input)\n",
    "    # Dropout layer\n",
    "    X = Dropout(0.2)(X)\n",
    "    # Apply maxpooling with a filter size of 2x2 and stride of 2\n",
    "    X = MaxPooling2D((2,2), strides = (2,2), name = \"max_pool1\")(X)\n",
    "    # Apply 16 5x5 filter convolution with stride of 1\n",
    "    X = Conv2D(16, (5,5), strides = (1,1), activation = \"relu\", name = \"conv2\")(X)\n",
    "    # Dropout layer\n",
    "    X = Dropout(0.2)(X)\n",
    "    # Apply maxpooling with a filter size of 2x2 and stride 2\n",
    "    X = MaxPooling2D((2,2), strides = (2,2), name = \"max_pool2\")(X)\n",
    "    \n",
    "    # Flatten X (convert to a vector) before going to fully\n",
    "    # connected layers\n",
    "    X = Flatten()(X)\n",
    "    # Apply fully connected layer with 120 neurons\n",
    "    X = Dense(120, activation=\"relu\", name = \"fc3\")(X)\n",
    "    # Dropout layer\n",
    "    X = Dropout(0.5)(X)\n",
    "    # Apply fully connected layer with 120 neurons\n",
    "    X = Dense(84, activation=\"relu\", name = \"fc5\")(X)\n",
    "    # Dropout layer\n",
    "    X = Dropout(0.5)(X)\n",
    "    \n",
    "    # Output a single binary classification\n",
    "    X = Dense(1, activation=\"sigmoid\", name = \"fc_out\")(X)\n",
    "    \n",
    "    # Create Keras model instance\n",
    "    model = Model(inputs = X_input, outputs = X, name=\"LeNet-5\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_dropout = model_with_dropout(images_train.shape[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_dropout.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_dropout.fit(x = images_train, y = labels_train, epochs = 8, batch_size = 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get accuracy on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dropout = model_with_dropout.evaluate(x = images_val, y = labels_val)\n",
    "print()\n",
    "print(\"Validation accuracy = \" + str(test_dropout[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_dropout = model_with_dropout.predict(images_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 149\n",
    "plt.imshow(images_test[index,:,:,:])\n",
    "print(\"Label: %i\"%labels_test[index])\n",
    "print(\"Prediction: %i\"%prediction_dropout[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(prediction_dropout)):\n",
    "    if prediction_dropout[i] == 1:\n",
    "        print(\"Predicted that \" + str(i) + \" was cholesteric.\")\n",
    "        \n",
    "for i in range(len(labels_test)):\n",
    "    if labels_test[i] == 1:\n",
    "        print(str(i) + \" actually was cholesteric.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance has gotten worse, now we never identify anything as cholesteric..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try the original model but stop training earlier to try avoid the overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_LeNet5_model = leNet5(images_train.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_LeNet5_model.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_LeNet5_model.fit(x = images_train, y = labels_train, epochs = 3, batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test = new_LeNet5_model.evaluate(x = images_val, y = labels_val)\n",
    "print()\n",
    "print(\"Validation accuracy = \" + str(new_test[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_prediction = new_LeNet5_model.predict(images_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 149\n",
    "plt.imshow(images_test[index,:,:,:])\n",
    "print(\"Label: %i\"%labels_test[index])\n",
    "print(\"Prediction: %i\"%new_prediction[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(new_prediction)):\n",
    "    if new_prediction[i] == 1:\n",
    "        print(\"Predicted that \" + str(i) + \" was cholesteric.\")\n",
    "        \n",
    "for i in range(len(labels_test)):\n",
    "    if labels_test[i] == 1:\n",
    "        print(str(i) + \" actually was cholesteric.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
