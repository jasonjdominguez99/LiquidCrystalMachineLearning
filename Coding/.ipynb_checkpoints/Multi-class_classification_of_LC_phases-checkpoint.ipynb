{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook was created at 21:42 16/10/20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi-class classification of liquid crystal phases using deep learning techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is the first attempt at classifying mutliple liquid crystal phases using deep learning - specifically a CNN architecture.\n",
    "The aim is to advance upon previous notebooks that attempted to preform various binary phase classification from LC textures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers.experimental.preprocessing import Rescaling\n",
    "from keras.preprocessing import image_dataset_from_directory\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 462 files belonging to 5 classes.\n",
      "Found 64 files belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "train_directory = \"C:/Users/Jason/Documents/University/Year_4/MPhys_Project(s)/Liquid_crystals-machine_learning/LiquidCrystalMachineLearning/Images_categorized/Train\"\n",
    "test_directory = \"C:/Users/Jason/Documents/University/Year_4/MPhys_Project(s)/Liquid_crystals-machine_learning/LiquidCrystalMachineLearning/Images_categorized/Test\"\n",
    "image_size = (368,640)\n",
    "\n",
    "train_dataset = image_dataset_from_directory(train_directory,\n",
    "                            labels=\"inferred\",\n",
    "                            label_mode=\"categorical\",\n",
    "                            color_mode=\"rgb\",\n",
    "                            batch_size=64,\n",
    "                            image_size=image_size,\n",
    "                            shuffle=True\n",
    "                        )\n",
    "val_dataset = image_dataset_from_directory(test_directory,\n",
    "                            labels=\"inferred\",\n",
    "                            label_mode=\"categorical\",\n",
    "                            color_mode=\"rgb\",\n",
    "                            batch_size=64,\n",
    "                            image_size=image_size,\n",
    "                            shuffle=True\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if the files imported as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TensorSpec(shape=(None, 368, 640, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 5), dtype=tf.float32, name=None))\n",
      "['0.Isotropic', '1.Nematic', '2.SmA', '3.SmF', '4.Cholesteric']\n",
      "(64, 368, 640, 3)\n",
      "<dtype: 'float32'>\n",
      "(64, 5)\n",
      "<dtype: 'float32'>\n",
      "(64, 368, 640, 3)\n",
      "<dtype: 'float32'>\n",
      "(64, 5)\n",
      "<dtype: 'float32'>\n",
      "(64, 368, 640, 3)\n",
      "<dtype: 'float32'>\n",
      "(64, 5)\n",
      "<dtype: 'float32'>\n",
      "(64, 368, 640, 3)\n",
      "<dtype: 'float32'>\n",
      "(64, 5)\n",
      "<dtype: 'float32'>\n",
      "(64, 368, 640, 3)\n",
      "<dtype: 'float32'>\n",
      "(64, 5)\n",
      "<dtype: 'float32'>\n",
      "(64, 368, 640, 3)\n",
      "<dtype: 'float32'>\n",
      "(64, 5)\n",
      "<dtype: 'float32'>\n",
      "(64, 368, 640, 3)\n",
      "<dtype: 'float32'>\n",
      "(64, 5)\n",
      "<dtype: 'float32'>\n",
      "(14, 368, 640, 3)\n",
      "<dtype: 'float32'>\n",
      "(14, 5)\n",
      "<dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.element_spec)\n",
    "print(train_dataset.class_names)\n",
    "for data, labels in train_dataset:\n",
    "    print(data.shape)\n",
    "    print(data.dtype)\n",
    "    print(labels.shape)\n",
    "    print(labels.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TensorSpec(shape=(None, 368, 640, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 5), dtype=tf.float32, name=None))\n",
      "['0.Isotropic', '1.Nematic', '2.SmA', '3.SmF', '4.Cholesteric']\n",
      "(64, 368, 640, 3)\n",
      "<dtype: 'float32'>\n",
      "(64, 5)\n",
      "<dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "print(val_dataset.element_spec)\n",
    "print(val_dataset.class_names)\n",
    "for data, labels in val_dataset:\n",
    "    print(data.shape)\n",
    "    print(data.dtype)\n",
    "    print(labels.shape)\n",
    "    print(labels.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define out pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shape = (image_size[0], image_size[1], 3)\n",
    "X_inputs = Input(shape = image_shape)\n",
    "# Rescale images to have values in range [0,1]\n",
    "X = Rescaling(scale = 1/255)(X_inputs)\n",
    "\n",
    "# Apply convolutional and pooling layers\n",
    "X = Conv2D(filters=32, kernel_size=(3,3), activation=\"relu\")(X)\n",
    "X = MaxPooling2D(pool_size=(3,3))(X)\n",
    "X = Conv2D(filters=32, kernel_size=(3,3), activation=\"relu\")(X)\n",
    "X = MaxPooling2D(pool_size=(3,3))(X)\n",
    "\n",
    "# Apply fully connected layer\n",
    "X = Flatten()(X)\n",
    "X = Dense(units=128, activation=\"relu\")(X)\n",
    "X = Dense(units=64, activation=\"relu\")(X)\n",
    "\n",
    "# Output layer\n",
    "num_classes = 5\n",
    "X_outputs = Dense(units=num_classes, activation=\"softmax\")(X)\n",
    "\n",
    "model = Model(inputs = X_inputs, outputs = X_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what this model looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 368, 640, 3)]     0         \n",
      "_________________________________________________________________\n",
      "rescaling_3 (Rescaling)      (None, 368, 640, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 366, 638, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 122, 212, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 120, 210, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 40, 70, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 89600)             0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 128)               11468928  \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 11,487,653\n",
      "Trainable params: 11,487,653\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to compile, train and test the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "8/8 [==============================] - 44s 6s/step - loss: 1.7772 - accuracy: 0.4437\n",
      "Epoch 2/3\n",
      "8/8 [==============================] - 44s 6s/step - loss: 0.7352 - accuracy: 0.7857\n",
      "Epoch 3/3\n",
      "8/8 [==============================] - 45s 6s/step - loss: 0.3661 - accuracy: 0.8918\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x208ca736748>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataset, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how the model does on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 9ms/step - loss: 2.3924 - accuracy: 0.3750\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the confusion matrix on our predictions to see where our model is struggling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(val_dataset)\n",
    "y_pred = np.argmax(predictions, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 4 3 3 3 4 2 4 4 4 1 4 4 3 4 2 1 2 0 4 1 4 4 3 1 1 4 2 1 2 2 1 1 1 0 1 2\n",
      " 2 3 3 2 0 0 2 4 3 2 1 0 4 2 4 3 2 4 2 4 2 1 0 0 4 4 2]\n",
      "[4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 1 4 4 0 4 4 4 4 4 4 4\n",
      " 4 0 4 4 4 4 4 4 4 4 4 0 4 4 4 4 4 4 0 0 4 4 1 4 4 4 4]\n",
      "Confusion matrix:\n",
      "[[0.14285714 0.14285714 0.         0.         0.71428571]\n",
      " [0.         0.         0.         0.         1.        ]\n",
      " [0.11764706 0.         0.         0.         0.88235294]\n",
      " [0.11111111 0.         0.         0.         0.88888889]\n",
      " [0.05263158 0.05263158 0.         0.         0.89473684]]\n"
     ]
    }
   ],
   "source": [
    "# Get true labels\n",
    "y_true = np.argmax(np.concatenate([labels for data, labels in val_dataset], axis=0), axis=1)\n",
    "print(y_true)\n",
    "print(y_pred)\n",
    "\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(y_true=y_true, y_pred=y_pred, normalize=\"true\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An imbalnced training dataset (many more cholesteric images than other phases) is one major flaw with the current model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
