{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook was created at 18:54 17/10/20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cholesteric or Nematic classification of liquid crystal phases using deep learning techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim is to advance upon previous notebooks that attempted to perform multi_class phase classification from LC textures by using a balanced dataset (only nematic and cholesteric due to a lack of images for other phases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers.experimental.preprocessing import Rescaling, Resizing\n",
    "from keras.preprocessing import image_dataset_from_directory\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 316 files belonging to 2 classes.\n",
      "Found 35 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_directory = \"C:/Users/Jason/Documents/University/Year_4/MPhys_Project(s)/Liquid_crystals-machine_learning/LiquidCrystalMachineLearning/Images_balanced/Train\"\n",
    "test_directory = \"C:/Users/Jason/Documents/University/Year_4/MPhys_Project(s)/Liquid_crystals-machine_learning/LiquidCrystalMachineLearning/Images_balanced/Test\"\n",
    "image_size = (368,640)\n",
    "\n",
    "train_dataset = image_dataset_from_directory(train_directory,\n",
    "                            labels=\"inferred\",\n",
    "                            label_mode=\"categorical\",\n",
    "                            color_mode=\"rgb\",\n",
    "                            batch_size=64,\n",
    "                            image_size=image_size,\n",
    "                            shuffle=True\n",
    "                        )\n",
    "val_dataset = image_dataset_from_directory(test_directory,\n",
    "                            labels=\"inferred\",\n",
    "                            label_mode=\"categorical\",\n",
    "                            color_mode=\"rgb\",\n",
    "                            batch_size=64,\n",
    "                            image_size=image_size,\n",
    "                            shuffle=True\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if the files imported as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TensorSpec(shape=(None, 368, 640, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 2), dtype=tf.float32, name=None))\n",
      "['Cholesteric', 'Nematic']\n",
      "(64, 368, 640, 3)\n",
      "<dtype: 'float32'>\n",
      "(64, 2)\n",
      "<dtype: 'float32'>\n",
      "(64, 368, 640, 3)\n",
      "<dtype: 'float32'>\n",
      "(64, 2)\n",
      "<dtype: 'float32'>\n",
      "(64, 368, 640, 3)\n",
      "<dtype: 'float32'>\n",
      "(64, 2)\n",
      "<dtype: 'float32'>\n",
      "(64, 368, 640, 3)\n",
      "<dtype: 'float32'>\n",
      "(64, 2)\n",
      "<dtype: 'float32'>\n",
      "(60, 368, 640, 3)\n",
      "<dtype: 'float32'>\n",
      "(60, 2)\n",
      "<dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.element_spec)\n",
    "print(train_dataset.class_names)\n",
    "for data, labels in train_dataset:\n",
    "    print(data.shape)\n",
    "    print(data.dtype)\n",
    "    print(labels.shape)\n",
    "    print(labels.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TensorSpec(shape=(None, 368, 640, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 2), dtype=tf.float32, name=None))\n",
      "['Cholesteric', 'Nematic']\n",
      "(35, 368, 640, 3)\n",
      "<dtype: 'float32'>\n",
      "(35, 2)\n",
      "<dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "print(val_dataset.element_spec)\n",
    "print(val_dataset.class_names)\n",
    "for data, labels in val_dataset:\n",
    "    print(data.shape)\n",
    "    print(data.dtype)\n",
    "    print(labels.shape)\n",
    "    print(labels.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define out pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shape = (image_size[0], image_size[1], 3)\n",
    "X_inputs = Input(shape = image_shape)\n",
    "# Rescale images to have values in range [0,1]\n",
    "X = Rescaling(scale = 1/255)(X_inputs)\n",
    "\n",
    "# Apply convolutional and pooling layers\n",
    "X = Conv2D(filters=32, kernel_size=(3,3), activation=\"relu\")(X)\n",
    "X = MaxPooling2D(pool_size=(3,3))(X)\n",
    "X = Conv2D(filters=32, kernel_size=(3,3), activation=\"relu\")(X)\n",
    "X = MaxPooling2D(pool_size=(3,3))(X)\n",
    "\n",
    "# Apply fully connected layer\n",
    "X = Flatten()(X)\n",
    "X = Dense(units=128, activation=\"relu\")(X)\n",
    "X = Dense(units=64, activation=\"relu\")(X)\n",
    "\n",
    "# Output layer\n",
    "num_classes = 2\n",
    "X_outputs = Dense(units=num_classes, activation=\"softmax\")(X)\n",
    "\n",
    "model = Model(inputs = X_inputs, outputs = X_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what this model looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        [(None, 368, 640, 3)]     0         \n",
      "_________________________________________________________________\n",
      "rescaling_9 (Rescaling)      (None, 368, 640, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 366, 638, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 122, 212, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 120, 210, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 40, 70, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 89600)             0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 128)               11468928  \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 11,487,458\n",
      "Trainable params: 11,487,458\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to compile, train and test the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "5/5 [==============================] - 28s 6s/step - loss: 0.0366 - accuracy: 0.9937\n",
      "Epoch 2/8\n",
      "5/5 [==============================] - 28s 6s/step - loss: 0.0199 - accuracy: 1.0000\n",
      "Epoch 3/8\n",
      "5/5 [==============================] - 28s 6s/step - loss: 0.0111 - accuracy: 0.9968\n",
      "Epoch 4/8\n",
      "5/5 [==============================] - 28s 6s/step - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 5/8\n",
      "5/5 [==============================] - 29s 6s/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 6/8\n",
      "5/5 [==============================] - 28s 6s/step - loss: 9.5194e-04 - accuracy: 1.0000\n",
      "Epoch 7/8\n",
      "5/5 [==============================] - 29s 6s/step - loss: 8.9849e-04 - accuracy: 1.0000\n",
      "Epoch 8/8\n",
      "5/5 [==============================] - 29s 6s/step - loss: 5.5756e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1fd84343408>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataset, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how the model does on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 1.1502 - accuracy: 0.7143\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the confusion matrix on our predictions to understand how our model is performing on the unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(val_dataset)\n",
    "y_pred = np.argmax(predictions, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 0 1 1 1 0 0 0 1 1 0 0 0 1 1 1 1 0 1 1 1 1 0 0 0 0 1]\n",
      "[1 0 0 0 1 0 0 0 1 1 1 0 0 1 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1]\n",
      "Confusion matrix:\n",
      "[[0.73684211 0.26315789]\n",
      " [0.5625     0.4375    ]]\n"
     ]
    }
   ],
   "source": [
    "# Get true labels\n",
    "y_true = np.argmax(np.concatenate([labels for data, labels in val_dataset], axis=0), axis=1)\n",
    "print(y_true)\n",
    "print(y_pred)\n",
    "\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(y_true=y_true, y_pred=y_pred, normalize=\"true\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An imbalnced training dataset (many more cholesteric images than other phases) is one major flaw with the current model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
